{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk4Cp-drMdbz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "plt.style.use('seaborn')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtnV1uJlEvAq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.layers import Input, Conv1D, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# 데이터 불러오기 및 전처리\n",
        "df = pd.read_csv('/content/drive/MyDrive/csv_file/2023_smartFarm_AI_hackathon_dataset.csv')\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['frmDist'] = encoder.fit_transform(df['frmDist'])\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
        "df[\"year\"] = df[\"date\"].dt.year\n",
        "df[\"month\"] = df[\"date\"].dt.month\n",
        "df[\"day\"] = df[\"date\"].dt.day\n",
        "\n",
        "# 시계열 데이터 선택 및 NumPy 배열로 변환\n",
        "normalized_data = df[['outtrn_cumsum', 'HeatingEnergyUsage_cumsum']].to_numpy()\n",
        "\n",
        "time_steps = 7\n",
        "n_series = normalized_data.shape[1]\n",
        "\n",
        "input_sequences = []\n",
        "target_values = []\n",
        "\n",
        "for i in range(len(normalized_data) - time_steps):\n",
        "    input_sequences.append(normalized_data[i:i+time_steps])\n",
        "    target_values.append(normalized_data[i+time_steps])\n",
        "\n",
        "input_sequences = np.array(input_sequences)\n",
        "target_values = np.array(target_values)\n",
        "\n",
        "# 데이터 분할\n",
        "split = int(0.8 * len(input_sequences))\n",
        "x_train = input_sequences[:split]\n",
        "y_train = target_values[:split]\n",
        "x_test = input_sequences[split:]\n",
        "y_test = target_values[split:]\n",
        "\n",
        "# 데이터 차원 변환 및 StandardScaler 적용\n",
        "x_train = x_train.reshape(-1, n_series)\n",
        "x_test = x_test.reshape(-1, n_series)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "x_train = x_train.reshape(-1, time_steps, n_series)\n",
        "x_test = x_test.reshape(-1, time_steps, n_series)\n",
        "\n",
        "# 모델 정의 (이하 모델 정의 및 학습 코드)\n",
        "inputs = Input(shape=(time_steps, n_series))\n",
        "conv_lstm_model = ConvLSTM(time_steps, n_series)\n",
        "outputs = conv_lstm_model(inputs)\n",
        "\n",
        "# 모델 학습 및 예측 (이하 학습 및 예측 코드)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlGHNWNoNMhj",
        "outputId": "a6dbc534-e555-4e53-81e2-17b32cad0fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"conv_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             multiple                  160       \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  8320      \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  1056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10098 (39.45 KB)\n",
            "Trainable params: 10098 (39.45 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class ConvLSTM(Model):\n",
        "    def __init__(self, time_steps, n_series):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "        self.conv1d = Conv1D(32, kernel_size=2)\n",
        "        self.lstm = LSTM(32)\n",
        "        self.dense1 = Dense(32, activation='relu')\n",
        "        self.dense2 = Dense(16, activation='relu')\n",
        "        self.dense3 = Dense(n_series, activation='linear')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1d(inputs)\n",
        "        x = self.lstm(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        outputs = self.dense3(x)\n",
        "        return outputs\n",
        "\n",
        "time_steps = 7\n",
        "n_series = 2\n",
        "\n",
        "inputs = Input(shape=(time_steps, n_series))\n",
        "conv_lstm_model = ConvLSTM(time_steps, n_series)\n",
        "outputs = conv_lstm_model(inputs)\n",
        "\n",
        "conv_lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xG2wMvnbDIh",
        "outputId": "1c3ef3a1-c38a-4b3f-9719-9af04b01b97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "955/955 [==============================] - 19s 6ms/step - loss: 155698167808.0000 - val_loss: 219302248448.0000\n",
            "Epoch 2/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 155374747648.0000 - val_loss: 218553008128.0000\n",
            "Epoch 3/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 154547339264.0000 - val_loss: 217124814848.0000\n",
            "Epoch 4/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 153301221376.0000 - val_loss: 215186931712.0000\n",
            "Epoch 5/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 151748689920.0000 - val_loss: 212479459328.0000\n",
            "Epoch 6/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 149256634368.0000 - val_loss: 208704864256.0000\n",
            "Epoch 7/100\n",
            "955/955 [==============================] - 7s 7ms/step - loss: 146270978048.0000 - val_loss: 204211961856.0000\n",
            "Epoch 8/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 142773010432.0000 - val_loss: 198865190912.0000\n",
            "Epoch 9/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 138625400832.0000 - val_loss: 192606486528.0000\n",
            "Epoch 10/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 133833515008.0000 - val_loss: 185409159168.0000\n",
            "Epoch 11/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 128450273280.0000 - val_loss: 177529159680.0000\n",
            "Epoch 12/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 122540204032.0000 - val_loss: 168882028544.0000\n",
            "Epoch 13/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 116036657152.0000 - val_loss: 159365971968.0000\n",
            "Epoch 14/100\n",
            "955/955 [==============================] - 9s 9ms/step - loss: 109037182976.0000 - val_loss: 149424996352.0000\n",
            "Epoch 15/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 101729026048.0000 - val_loss: 139084922880.0000\n",
            "Epoch 16/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 94084308992.0000 - val_loss: 128372244480.0000\n",
            "Epoch 17/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 86368215040.0000 - val_loss: 117727870976.0000\n",
            "Epoch 18/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 78851317760.0000 - val_loss: 107451924480.0000\n",
            "Epoch 19/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 71614971904.0000 - val_loss: 97597399040.0000\n",
            "Epoch 20/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 64709492736.0000 - val_loss: 88199659520.0000\n",
            "Epoch 21/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 58243637248.0000 - val_loss: 79555846144.0000\n",
            "Epoch 22/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 52367642624.0000 - val_loss: 71778353152.0000\n",
            "Epoch 23/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 47181504512.0000 - val_loss: 64892297216.0000\n",
            "Epoch 24/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 42741329920.0000 - val_loss: 59129401344.0000\n",
            "Epoch 25/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 39129227264.0000 - val_loss: 54709002240.0000\n",
            "Epoch 26/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 36346482688.0000 - val_loss: 51007504384.0000\n",
            "Epoch 27/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 34282278912.0000 - val_loss: 48481226752.0000\n",
            "Epoch 28/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 32862844928.0000 - val_loss: 46726270976.0000\n",
            "Epoch 29/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 31921070080.0000 - val_loss: 45540245504.0000\n",
            "Epoch 30/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 31275008000.0000 - val_loss: 44765310976.0000\n",
            "Epoch 31/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 30819317760.0000 - val_loss: 44178341888.0000\n",
            "Epoch 32/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 30457823232.0000 - val_loss: 43790905344.0000\n",
            "Epoch 33/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 30151352320.0000 - val_loss: 43120476160.0000\n",
            "Epoch 34/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 29574137856.0000 - val_loss: 42462208000.0000\n",
            "Epoch 35/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 29119047680.0000 - val_loss: 41899667456.0000\n",
            "Epoch 36/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 28843210752.0000 - val_loss: 41511653376.0000\n",
            "Epoch 37/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 28586092544.0000 - val_loss: 41182302208.0000\n",
            "Epoch 38/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 28364056576.0000 - val_loss: 40985092096.0000\n",
            "Epoch 39/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 28131147776.0000 - val_loss: 40589484032.0000\n",
            "Epoch 40/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 27935125504.0000 - val_loss: 40239153152.0000\n",
            "Epoch 41/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 27789821952.0000 - val_loss: 40078200832.0000\n",
            "Epoch 42/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 27646244864.0000 - val_loss: 40008691712.0000\n",
            "Epoch 43/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 27505025024.0000 - val_loss: 39734685696.0000\n",
            "Epoch 44/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 27335907328.0000 - val_loss: 39432876032.0000\n",
            "Epoch 45/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 27177947136.0000 - val_loss: 39169908736.0000\n",
            "Epoch 46/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 27016753152.0000 - val_loss: 39490215936.0000\n",
            "Epoch 47/100\n",
            "955/955 [==============================] - 7s 7ms/step - loss: 26907121664.0000 - val_loss: 39005851648.0000\n",
            "Epoch 48/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 26813530112.0000 - val_loss: 38879481856.0000\n",
            "Epoch 49/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 26649452544.0000 - val_loss: 38934953984.0000\n",
            "Epoch 50/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 26555842560.0000 - val_loss: 38132899840.0000\n",
            "Epoch 51/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 26255769600.0000 - val_loss: 37864378368.0000\n",
            "Epoch 52/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 26124634112.0000 - val_loss: 37819576320.0000\n",
            "Epoch 53/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 26037499904.0000 - val_loss: 37457866752.0000\n",
            "Epoch 54/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 25888014336.0000 - val_loss: 37227679744.0000\n",
            "Epoch 55/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 25654478848.0000 - val_loss: 36966559744.0000\n",
            "Epoch 56/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 25567279104.0000 - val_loss: 36839153664.0000\n",
            "Epoch 57/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 25417488384.0000 - val_loss: 37356498944.0000\n",
            "Epoch 58/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 25389428736.0000 - val_loss: 36471545856.0000\n",
            "Epoch 59/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 25266345984.0000 - val_loss: 36362006528.0000\n",
            "Epoch 60/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 25115205632.0000 - val_loss: 36384747520.0000\n",
            "Epoch 61/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 25082447872.0000 - val_loss: 36139098112.0000\n",
            "Epoch 62/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 24965195776.0000 - val_loss: 35914899456.0000\n",
            "Epoch 63/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 24933482496.0000 - val_loss: 36401623040.0000\n",
            "Epoch 64/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 24795600896.0000 - val_loss: 36452306944.0000\n",
            "Epoch 65/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 24705720320.0000 - val_loss: 35703476224.0000\n",
            "Epoch 66/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 24618557440.0000 - val_loss: 35726848000.0000\n",
            "Epoch 67/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 24543453184.0000 - val_loss: 35340083200.0000\n",
            "Epoch 68/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 24475529216.0000 - val_loss: 35206594560.0000\n",
            "Epoch 69/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 24362579968.0000 - val_loss: 34947067904.0000\n",
            "Epoch 70/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 24227932160.0000 - val_loss: 35074850816.0000\n",
            "Epoch 71/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 24141697024.0000 - val_loss: 34784845824.0000\n",
            "Epoch 72/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 24136525824.0000 - val_loss: 34513006592.0000\n",
            "Epoch 73/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 23992004608.0000 - val_loss: 34536472576.0000\n",
            "Epoch 74/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 23890563072.0000 - val_loss: 34514894848.0000\n",
            "Epoch 75/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 23807711232.0000 - val_loss: 34423857152.0000\n",
            "Epoch 76/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 23730808832.0000 - val_loss: 34025570304.0000\n",
            "Epoch 77/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 23646054400.0000 - val_loss: 33935640576.0000\n",
            "Epoch 78/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 23550285824.0000 - val_loss: 33873174528.0000\n",
            "Epoch 79/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 23459821568.0000 - val_loss: 33549402112.0000\n",
            "Epoch 80/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 23349616640.0000 - val_loss: 33736460288.0000\n",
            "Epoch 81/100\n",
            "955/955 [==============================] - 8s 8ms/step - loss: 23288875008.0000 - val_loss: 33527789568.0000\n",
            "Epoch 82/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 23213195264.0000 - val_loss: 33465372672.0000\n",
            "Epoch 83/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 23097884672.0000 - val_loss: 33148497920.0000\n",
            "Epoch 84/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 22974121984.0000 - val_loss: 33489293312.0000\n",
            "Epoch 85/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 22828097536.0000 - val_loss: 32669757440.0000\n",
            "Epoch 86/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 22733445120.0000 - val_loss: 32373901312.0000\n",
            "Epoch 87/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 22524440576.0000 - val_loss: 32385970176.0000\n",
            "Epoch 88/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 22461986816.0000 - val_loss: 32244914176.0000\n",
            "Epoch 89/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 22409697280.0000 - val_loss: 31915067392.0000\n",
            "Epoch 90/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 22314305536.0000 - val_loss: 31936663552.0000\n",
            "Epoch 91/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 22213808128.0000 - val_loss: 32084600832.0000\n",
            "Epoch 92/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 22140321792.0000 - val_loss: 31774371840.0000\n",
            "Epoch 93/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 22017873920.0000 - val_loss: 31538968576.0000\n",
            "Epoch 94/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 21995423744.0000 - val_loss: 31493756928.0000\n",
            "Epoch 95/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 21905100800.0000 - val_loss: 31252439040.0000\n",
            "Epoch 96/100\n",
            "955/955 [==============================] - 5s 6ms/step - loss: 21835448320.0000 - val_loss: 31222226944.0000\n",
            "Epoch 97/100\n",
            "955/955 [==============================] - 7s 7ms/step - loss: 21756254208.0000 - val_loss: 31826544640.0000\n",
            "Epoch 98/100\n",
            "955/955 [==============================] - 5s 5ms/step - loss: 21702381568.0000 - val_loss: 30851446784.0000\n",
            "Epoch 99/100\n",
            "955/955 [==============================] - 6s 7ms/step - loss: 21572739072.0000 - val_loss: 30892621824.0000\n",
            "Epoch 100/100\n",
            "955/955 [==============================] - 6s 6ms/step - loss: 21574346752.0000 - val_loss: 30775480320.0000\n",
            "531/531 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7949f15a05d2>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredicted_values_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_values1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 예측 결과와 실제 값 사이의 RMSE 값 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=3e-4), loss='mean_squared_error')\n",
        "\n",
        "history=model.fit(x_train, y_train,\n",
        "          epochs=100,\n",
        "          batch_size=64,\n",
        "          validation_split=0.1,\n",
        "          )\n",
        "\n",
        "predicted_values1 = model.predict(x_test)\n",
        "\n",
        "predicted_values_original = scaler.inverse_transform(predicted_values1)\n",
        "\n",
        "r2 = r2_score(y_test, predicted_values1)\n",
        "\n",
        "# 예측 결과와 실제 값 사이의 RMSE 값 계산\n",
        "rmse = np.sqrt(mean_squared_error(y_test, predicted_values1))\n",
        "\n",
        "print(f\"R2 Score: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opQpcipOT1aK"
      },
      "outputs": [],
      "source": [
        "initial_input = input_sequences[-1] ## LAST INPUT SEQUENCE\n",
        "num_iterations = 50\n",
        "forecasts = []\n",
        "for _ in range(num_iterations):\n",
        "    forecast = model.predict(np.expand_dims(initial_input, axis=0))[0]\n",
        "    forecast_original = scaler.inverse_transform(forecast.reshape(1, -1))\n",
        "    forecasts.append(forecast_original[0])\n",
        "    initial_input = np.concatenate((initial_input[1:], forecast.reshape(1, -1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCZnLvd60bjw"
      },
      "outputs": [],
      "source": [
        "final_forecasts = np.array(forecasts)\n",
        "r2_forecasts = r2_score(y_test[:len(final_forecasts)], final_forecasts)\n",
        "\n",
        "# 예측 결과와 실제 값 사이의 RMSE 값 계산\n",
        "rmse_forecasts = np.sqrt(mean_squared_error(y_test[:len(final_forecasts)], final_forecasts))\n",
        "\n",
        "print(f\"R2 Score for Forecasts: {r2_forecasts}\")\n",
        "print(f\"RMSE for Forecasts: {rmse_forecasts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO2y2stY0iMG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}